{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp_OwfpTpAKm",
    "outputId": "855d7e1c-9730-4659-a89c-922a84efb5f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 19:18:45,579 - IrisClassification - INFO - Loading and preprocessing data...\n",
      "2024-11-25 19:18:45,585 - IrisClassification - INFO - Data preprocessing completed successfully\n",
      "2024-11-25 19:18:45,585 - IrisClassification - INFO - Training Random Forest Classifier...\n",
      "2024-11-25 19:18:45,695 - IrisClassification - INFO - Model trained and saved to models/rf_model_20241125_191845.pkl\n",
      "2024-11-25 19:18:45,696 - IrisClassification - INFO - Evaluating model performance...\n",
      "2024-11-25 19:18:45,715 - IrisClassification - INFO - Model Accuracy: 1.0000\n",
      "2024-11-25 19:18:45,715 - IrisClassification - INFO - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "2024-11-25 19:18:45,717 - IrisClassification - INFO - Checking for data drift...\n",
      "/home/sain/miniforge3/envs/mlops/lib/python3.13/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2024-11-25 19:18:45,719 - IrisClassification - WARNING - Drift detected in feature sepal length (cm): KS statistic = 0.7200, p-value = 0.0000\n",
      "2024-11-25 19:18:45,720 - IrisClassification - WARNING - Drift detected in feature sepal width (cm): KS statistic = 0.3800, p-value = 0.0013\n",
      "2024-11-25 19:18:45,721 - IrisClassification - WARNING - Drift detected in feature petal length (cm): KS statistic = 0.8800, p-value = 0.0000\n",
      "2024-11-25 19:18:45,721 - IrisClassification - WARNING - Drift detected in feature petal width (cm): KS statistic = 0.8400, p-value = 0.0000\n",
      "2024-11-25 19:18:45,723 - IrisClassification - INFO - Making predictions...\n",
      "/home/sain/miniforge3/envs/mlops/lib/python3.13/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2024-11-25 19:18:45,753 - IrisClassification - INFO - Prediction 1: Class=setosa (Probability=1.0000)\n",
      "2024-11-25 19:18:45,753 - IrisClassification - INFO - Prediction 2: Class=setosa (Probability=1.0000)\n",
      "2024-11-25 19:18:45,754 - IrisClassification - INFO - Prediction 3: Class=setosa (Probability=1.0000)\n",
      "2024-11-25 19:18:45,754 - IrisClassification - INFO - Prediction 4: Class=setosa (Probability=1.0000)\n",
      "2024-11-25 19:18:45,754 - IrisClassification - INFO - Prediction 5: Class=setosa (Probability=1.0000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "from typing import Tuple, Dict, Any\n",
    "import pickle\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "class IrisClassificationSystem:\n",
    "    def __init__(self, log_dir: str = \"logs\", model_dir: str = \"models\"):\n",
    "        \"\"\"Initialize the classification system with logging and monitoring.\"\"\"\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        self.log_dir = log_dir\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "        # Setup logging\n",
    "        self.setup_logging()\n",
    "\n",
    "        # Initialize model and scaler\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        self.target_names = None\n",
    "\n",
    "        # Performance thresholds for monitoring\n",
    "        self.accuracy_threshold = 0.9\n",
    "        self.drift_threshold = 0.05\n",
    "\n",
    "        # Store baseline statistics\n",
    "        self.baseline_stats = {}\n",
    "\n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configure logging with both file and console handlers.\"\"\"\n",
    "        self.logger = logging.getLogger('IrisClassification')\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        # Create handlers\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        fh = logging.FileHandler(f'{self.log_dir}/iris_classification_{timestamp}.log')\n",
    "        ch = logging.StreamHandler()\n",
    "\n",
    "        # Create formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        fh.setFormatter(formatter)\n",
    "        ch.setFormatter(formatter)\n",
    "\n",
    "        # Add handlers\n",
    "        self.logger.addHandler(fh)\n",
    "        self.logger.addHandler(ch)\n",
    "\n",
    "    def load_and_preprocess_data(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Load and preprocess the Iris dataset.\"\"\"\n",
    "        self.logger.info(\"Loading and preprocessing data...\")\n",
    "\n",
    "        try:\n",
    "            # Load dataset\n",
    "            iris = load_iris()\n",
    "            X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "            y = iris.target\n",
    "\n",
    "            self.feature_names = iris.feature_names\n",
    "            self.target_names = iris.target_names\n",
    "\n",
    "            # Split the data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "\n",
    "            # Scale the features\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "\n",
    "            # Store baseline statistics\n",
    "            self.baseline_stats = {\n",
    "                'feature_means': X_train_scaled.mean(axis=0).tolist(),\n",
    "                'feature_stds': X_train_scaled.std(axis=0).tolist(),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "            self.logger.info(\"Data preprocessing completed successfully\")\n",
    "            return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in data preprocessing: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def train_model(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "        \"\"\"Train the Random Forest model.\"\"\"\n",
    "        self.logger.info(\"Training Random Forest Classifier...\")\n",
    "\n",
    "        try:\n",
    "            self.model = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            self.model.fit(X_train, y_train)\n",
    "\n",
    "            # Save the model\n",
    "            model_path = f\"{self.model_dir}/rf_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump((self.model, self.scaler), f)\n",
    "\n",
    "            self.logger.info(f\"Model trained and saved to {model_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in model training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"Evaluate the model and log performance metrics.\"\"\"\n",
    "        self.logger.info(\"Evaluating model performance...\")\n",
    "\n",
    "        try:\n",
    "            # Make predictions\n",
    "            y_pred = self.model.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            class_report = classification_report(y_test, y_pred, target_names=self.target_names)\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            # Log metrics\n",
    "            metrics = {\n",
    "                'accuracy': accuracy,\n",
    "                'classification_report': class_report,\n",
    "                'confusion_matrix': conf_matrix.tolist(),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "            # Save metrics to file\n",
    "            metrics_path = f\"{self.log_dir}/metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            with open(metrics_path, 'w') as f:\n",
    "                json.dump(metrics, f, indent=4)\n",
    "\n",
    "            self.logger.info(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "            self.logger.info(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "            # Check if accuracy is below threshold\n",
    "            if accuracy < self.accuracy_threshold:\n",
    "                self.logger.warning(f\"Model accuracy {accuracy:.4f} is below threshold {self.accuracy_threshold}\")\n",
    "\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in model evaluation: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def detect_drift(self, new_data: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Detect potential data drift using Kolmogorov-Smirnov test.\"\"\"\n",
    "        self.logger.info(\"Checking for data drift...\")\n",
    "\n",
    "        try:\n",
    "            # Scale new data\n",
    "            new_data_scaled = self.scaler.transform(new_data)\n",
    "\n",
    "            drift_scores = {}\n",
    "            for i, feature in enumerate(self.feature_names):\n",
    "                # Perform KS test\n",
    "                ks_statistic, p_value = ks_2samp(\n",
    "                    new_data_scaled[:, i],\n",
    "                    np.random.normal(\n",
    "                        self.baseline_stats['feature_means'][i],\n",
    "                        self.baseline_stats['feature_stds'][i],\n",
    "                        size=len(new_data_scaled)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                drift_scores[feature] = {\n",
    "                    'ks_statistic': float(ks_statistic),\n",
    "                    'p_value': float(p_value)\n",
    "                }\n",
    "\n",
    "                # Alert if significant drift detected\n",
    "                if p_value < self.drift_threshold:\n",
    "                    self.logger.warning(f\"Drift detected in feature {feature}: KS statistic = {ks_statistic:.4f}, p-value = {p_value:.4f}\")\n",
    "\n",
    "            return drift_scores\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in drift detection: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Make predictions with logging.\"\"\"\n",
    "        self.logger.info(\"Making predictions...\")\n",
    "\n",
    "        try:\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            predictions = self.model.predict(X_scaled)\n",
    "            probabilities = self.model.predict_proba(X_scaled)\n",
    "\n",
    "            # Log predictions\n",
    "            for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "                self.logger.info(f\"Prediction {i+1}: Class={self.target_names[pred]} (Probability={max(prob):.4f})\")\n",
    "\n",
    "            return predictions\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in prediction: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the system\n",
    "    iris_system = IrisClassificationSystem()\n",
    "\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = iris_system.load_and_preprocess_data()\n",
    "\n",
    "    # Train the model\n",
    "    iris_system.train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    metrics = iris_system.evaluate_model(X_test, y_test)\n",
    "\n",
    "    # Example of drift detection\n",
    "    iris_system.detect_drift(load_iris().data[:50])\n",
    "\n",
    "    # Example prediction\n",
    "    sample_data = load_iris().data[:5]\n",
    "    predictions = iris_system.predict(sample_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
